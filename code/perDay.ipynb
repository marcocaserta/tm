{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import glob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from os import path, listdir\n",
    "import collections\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "folder = \"NEWS_TXT_v4/\"\n",
    "perDayFolders = \"v4/\"\n",
    "prefix = path.expanduser(\"~/gdrive/research/nlp/data/\")\n",
    "vocab_folder = \"google_vocab/\"\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Four Tasks\n",
    "\n",
    "-  Task 1: Files Preprocessing. Each press release should be preprocessed and stored on disk. These preprocessed files are the ones used to create the doc2vec model\n",
    "-  Task 2: doc2vec Model Generation. Progressively create doc2vec models, from year 0 to year \"t\", where t=1994,...,2015. These doc2vec models are stored within each year directory.\n",
    "-  Task 3: Distance Matrix Computation. Given a time period (a day, a month, etc.) load all the files belonging to that period (the corpus) and compute the distance matrix. This matric could be stored on disk.\n",
    "-  Task 4: Clustering. Use the distance matrix to carry out specific studies of press releases over time.\n",
    "\n",
    "In addition, there is also a Task 0, which is the restructuring and organization of the different folders. This is the first task carried out below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task 0: Restructuring Directories and Moving Files\n",
    "\n",
    "Move each file in the corresponding year folder and, within the year, the corresponding day and month. For example, a file issued on January 21st, 2015 will be stored in the folder:\n",
    "\n",
    "-  2015/01_21/fullname.txt\n",
    "\n",
    "We also create a global mapping for all the files in the dataset. The mapping gives a unique identifier for each file in the dataset and it is saved in the file `mapping.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fmap = open(\"mapping.txt\", \"w\")\n",
    "\n",
    "fullpath = path.join(prefix,folder)\n",
    "for f in listdir(fullpath):\n",
    "    print(\"name is = \", f)\n",
    "    \n",
    "    fName = f[:-4]\n",
    "    print(\"Now fName is = \", fName)\n",
    "    fAux = fName.split(\"_\")\n",
    "    print(fAux)\n",
    "    year = fAux[1]\n",
    "    dirLevel1 = path.join(prefix,perDayFolders) + year\n",
    "    if not os.path.exists(dirLevel1):\n",
    "        os.makedirs(dirLevel1)\n",
    "    dirLevel2 = dirLevel1 + \"/\" + fAux[2] + \"_\" + fAux[3]\n",
    "    fmap.write(\"{0}\\t {1}\\t {2}\\t {3}\\t {4}\\n\".format(f,fAux[0],fAux[1],fAux[2],fAux[3]))\n",
    "    if not os.path.exists(dirLevel2):\n",
    "        os.makedirs(dirLevel2)\n",
    "    origin = fullpath + f\n",
    "    dest   = dirLevel2 + \"/\" + f\n",
    "    shutil.copy2(origin, dest)\n",
    "    print(\"copying from \", origin, \" to \", dest)\n",
    "    \n",
    "fmap.close()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task 1: Files Preprocessing\n",
    "\n",
    "We now get into each directory of the current year, and add each file within that directory to the corpus. In addition, we write a _preprocessed_ version of the file (suffix `.pre`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let us first import the mapping filename $\\rightarrow$ tag. Here we are reading the whole list, i.e., the entire dataset. We define two structures to query the filename and the absolute id value:\n",
    "-  `file2tag`: Given a file name, it returns the corresponding unique identifier\n",
    "-  `tag2file`: Given a unique identifier, i.e., a tag, it returns the full file name (cik_year_month_day.txt)\n",
    "\n",
    "We also create a dataframe, `dfMap`, which contains all the information associated to a specific file, i.e., full name, cik, year, month, day, tag.\n",
    "\n",
    "For the preprocessing phase, we use the following criteria:\n",
    "- exclude all words with length $\\leq$ 2\n",
    "- exclude all words that are not alphabetic (`isalpha()` from nltk)\n",
    "- exclude stopwords\n",
    "- exclude all words which are not in the google news dictionary (cut to the 500k most frequent words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fullpath = path.join(prefix,vocab_folder)\n",
    "name_vocab = fullpath + \"embed500.vocab\"\n",
    "with open(name_vocab) as f:\n",
    "    vocab_list = map(str.strip,f.readlines())\n",
    "vocab_dict = {w:k for k,w in enumerate(vocab_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nRows = sum(1 for line in open('mapping.txt'))\n",
    "dfMap = pd.DataFrame(index=np.arange(0, nRows), columns=('name', 'cik', 'year', 'month','day','tag') )\n",
    "\n",
    "with open(\"mapping.txt\", \"r\") as f:\n",
    "    row = 0\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        line=line.rstrip() # remove \\n from each row\n",
    "        dfMap.loc[row] = line.split(\",\")\n",
    "        row += 1\n",
    "dfMap[\"year\"] = dfMap[\"year\"].astype(\"int\")   \n",
    "dfMap[\"month\"] = dfMap[\"month\"].astype(\"int\")   \n",
    "dfMap[\"day\"] = dfMap[\"day\"].astype(\"int\")   \n",
    "dfMap[\"tag\"] = dfMap[\"tag\"].astype(\"int\")   \n",
    "#print(dfMap.dtypes)\n",
    "file2tag = {f:t for f,t in zip(dfMap[\"name\"],dfMap[\"tag\"])}\n",
    "tag2file = {t:f for t,f in zip(dfMap[\"tag\"],dfMap[\"name\"])}\n",
    "\n",
    "#print(file2tag[\"11544_1996_12_13.txt\"])\n",
    "#print(tag2file[\"10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      723371_1995_08_11.txt   723371  1995   8  11    0\n",
      "0     352510_1995_09_22.txt   352510  1995   9  22    1\n",
      "1     723926_1996_06_04.txt   723926  1996   6   4    2\n",
      "2     873364_1996_06_14.txt   873364  1996   6  14    3\n",
      "3      32017_1996_06_20.txt    32017  1996   6  20    4\n",
      "4      69598_1996_06_24.txt    69598  1996   6  24    5\n",
      "5     893670_1996_07_12.txt   893670  1996   7  12    6\n",
      "6      42872_1996_08_09.txt    42872  1996   8   9    7\n",
      "7     770975_1996_10_18.txt   770975  1996  10  18    8\n",
      "8     943358_1996_11_26.txt   943358  1996  11  26    9\n",
      "9      11544_1996_12_13.txt    11544  1996  12  13   10\n",
      "10    899689_1997_03_26.txt   899689  1997   3  26   11\n",
      "11   1000301_1997_05_13.txt  1000301  1997   5  13   12\n",
      "12     43512_1997_05_22.txt    43512  1997   5  22   13\n",
      "13    933730_1997_05_23.txt   933730  1997   5  23   14\n",
      "14    351127_1997_06_19.txt   351127  1997   6  19   15\n",
      "15    106640_1997_07_17.txt   106640  1997   7  17   16\n",
      "16    922519_1997_07_17.txt   922519  1997   7  17   17\n",
      "17    874263_1997_08_06.txt   874263  1997   8   6   18\n",
      "18    894076_1997_10_27.txt   894076  1997  10  27   19\n",
      "19    866273_1997_12_19.txt   866273  1997  12  19   20\n",
      "20    891504_1998_01_12.txt   891504  1998   1  12   21\n",
      "21    100885_1998_01_23.txt   100885  1998   1  23   22\n",
      "22    922471_1998_01_30.txt   922471  1998   1  30   23\n",
      "23    948850_1998_03_09.txt   948850  1998   3   9   24\n",
      "24    320443_1998_04_22.txt   320443  1998   4  22   25\n",
      "25   1005126_1998_04_22.txt  1005126  1998   4  22   26\n",
      "26    860730_1998_05_28.txt   860730  1998   5  28   27\n",
      "27    912192_1998_08_19.txt   912192  1998   8  19   28\n",
      "28    924174_1998_09_02.txt   924174  1998   9   2   29\n",
      "29     48948_1998_10_16.txt    48948  1998  10  16   30\n",
      "..                      ...      ...   ...  ..  ..  ...\n",
      "969  1564822_2014_12_10.txt  1564822  2014  12  10  970\n",
      "970  1357204_2014_12_18.txt  1357204  2014  12  18  971\n",
      "971  1338613_2015_01_26.txt  1338613  2015   1  26  972\n",
      "972   854560_2015_01_29.txt   854560  2015   1  29  973\n",
      "973   878927_2015_02_05.txt   878927  2015   2   5  974\n",
      "974  1511737_2015_02_05.txt  1511737  2015   2   5  975\n",
      "975    29644_2015_02_24.txt    29644  2015   2  24  976\n",
      "976    38984_2015_02_25.txt    38984  2015   2  25  977\n",
      "977   809248_2015_02_26.txt   809248  2015   2  26  978\n",
      "978  1604028_2015_03_03.txt  1604028  2015   3   3  979\n",
      "979  1451514_2015_03_23.txt  1451514  2015   3  23  980\n",
      "980  1048911_2015_04_09.txt  1048911  2015   4   9  981\n",
      "981  1508171_2015_04_09.txt  1508171  2015   4   9  982\n",
      "982  1102112_2015_04_14.txt  1102112  2015   4  14  983\n",
      "983  1450390_2015_04_15.txt  1450390  2015   4  15  984\n",
      "984     7332_2015_04_23.txt     7332  2015   4  23  985\n",
      "985   882154_2015_04_24.txt   882154  2015   4  24  986\n",
      "986   912242_2015_04_29.txt   912242  2015   4  29  987\n",
      "987    75829_2015_05_13.txt    75829  2015   5  13  988\n",
      "988  1309082_2015_05_15.txt  1309082  2015   5  15  989\n",
      "989    29644_2015_06_30.txt    29644  2015   6  30  990\n",
      "990  1301063_2015_07_02.txt  1301063  2015   7   2  991\n",
      "991  1495536_2015_07_08.txt  1495536  2015   7   8  992\n",
      "992  1278027_2015_07_13.txt  1278027  2015   7  13  993\n",
      "993  1504619_2015_08_06.txt  1504619  2015   8   6  994\n",
      "994  1636050_2015_08_11.txt  1636050  2015   8  11  995\n",
      "995  1080319_2015_09_24.txt  1080319  2015   9  24  996\n",
      "996   779152_2015_11_04.txt   779152  2015  11   4  997\n",
      "997  1173281_2015_11_12.txt  1173281  2015  11  12  998\n",
      "998  1305014_2015_11_18.txt  1305014  2015  11  18  999\n",
      "\n",
      "[999 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"mapping.txt\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "year0 = \"2014\"\n",
    "yearT = \"2015\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "yearSet = list(range(int(year0), int(yearT)+1))\n",
    "\n",
    "for year in yearSet:\n",
    "    \n",
    "    dirFull = path.join(prefix,perDayFolders) + str(year)\n",
    "    print(dirFull)\n",
    "\n",
    "    for ff in listdir(dirFull):\n",
    "        print(\"Entering folder \", ff)\n",
    "        filteredList = path.join(dirFull,ff) + \"/*.txt\"\n",
    "        for f in glob.glob(filteredList):\n",
    "\n",
    "            fullname = path.join(dirFull,ff,f)\n",
    "            if os.path.isfile(fullname+\".pre\"):\n",
    "                continue\n",
    "\n",
    "            fTxt = open(fullname)\n",
    "            doc = fTxt.read()\n",
    "            words = [w.lower() for w in word_tokenize(doc) if w not in stop_words]\n",
    "            words = [w for w in words if len(w) > 2 and w.isalpha() and w in vocab_dict]\n",
    "\n",
    "            preprocName = fullname+\".pre\"\n",
    "            fPre = open(preprocName, \"w\")\n",
    "            writerDoc = csv.writer(fPre)\n",
    "            writerDoc.writerows([words])\n",
    "            fPre.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"bae\" in vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task 2: doc2vec model creation\n",
    "\n",
    "We now need to read all the files belonging to a given year (later, up to that year) and build a doc2vec model to be used with the documents of that year. The doc2vect model is stored within the folder of that year and a suffix `.year` is added to each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format='%(asctime)s : %(threadName)s : %(levelname)s : %(message)s',\n",
    "        level=logging.INFO\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[NOT NEEDED ANYMORE] First, let us define a function used to determine whether a certain document matches the criteria used to define which documents will be employed to build the distance matrix (typically, year-month-day or any subset of that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def isSelected(name, year, month, day):\n",
    "    name= name[:-4]\n",
    "    cik, yy, mm, dd = name.split(\"_\")\n",
    "    if yy == year:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we import all the preprocessed files relative to the period considered in the construction of the doc2vec model.\n",
    "\n",
    "**Rem.:** To build the doc2vec model, we use all the files in the period year0 to yearT. However, the distance matrix computation only includes the document in a prespecified period, e.g., a year, or a day. For this reason, we define here a new dictionary, called `corpus2tag`, which is used to identify which documents of the current corpus belong to a given time window. There are the only documents for which we want to compute the distance matrix.\n",
    "\n",
    "Two tags:\n",
    "-  the fist is the id number within the corpus\n",
    "-  the second is the absolute id number, i.e., within the entire dataset\n",
    "\n",
    "Each document embedding can be accessed via any of the two tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering year  2014\n",
      "Corpus with    40 documents.\n",
      "Considering year  2015\n",
      "Corpus with    68 documents.\n"
     ]
    }
   ],
   "source": [
    "yearT = \"2015\"\n",
    "year0 = \"2014\"\n",
    "yearSet = list(range(int(year0), int(yearT)+1))\n",
    "\n",
    "docs = []\n",
    "tagsAbs = []\n",
    "corpusID = []\n",
    "absID = []\n",
    "analyzedDocument = namedtuple('AnalyzedDocument','words tags')\n",
    "i = 0\n",
    "for year in yearSet:\n",
    "    print(\"Considering year \", year)\n",
    "    dirFull = path.join(prefix,perDayFolders) + str(year)\n",
    " \n",
    "    for ff in listdir(dirFull):\n",
    "        filteredList = path.join(dirFull,ff) + \"/*.txt.pre\"\n",
    "        for f in glob.glob(filteredList):\n",
    "            name = f.split(\"/\")[-1]\n",
    "            name = name[:-4]\n",
    "            #selected = 0\n",
    "            #print(name, file2tag[name])\n",
    "            #if isSelected(name, yearT, [], []):\n",
    "            #    corpusID.append(i)\n",
    "            #    absID.append(file2tag[name])\n",
    "            #    selected = 1\n",
    "                \n",
    "            fullname = path.join(dirFull, ff, f)\n",
    "            fToken = open(fullname, \"r\")\n",
    "            readerDoc = csv.reader(fToken)\n",
    "            doc = next(readerDoc)\n",
    "            fToken.close()\n",
    "            #tags = [i,str(file2tag[name])]\n",
    "            tags = [str(file2tag[name])] \n",
    "            #absID.append(file2tag[name])\n",
    "            docs.append(analyzedDocument(doc,tags))\n",
    "\n",
    "            i = i + 1\n",
    "    print(\"Corpus with {0:5d} documents.\".format(len(docs)))\n",
    "\n",
    "#corpus2tag = {id:t for id,t in zip(corpusID,absID)}\n",
    "#print(\"List of documents included in the considered time window::\")\n",
    "#print(corpus2tag)\n",
    "#verify\n",
    "#print(docs[64])\n",
    "#print(tag2file[corpus2tag[64]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-05 09:26:17,214 : MainThread : INFO : collecting all words and their counts\n",
      "2018-04-05 09:26:17,215 : MainThread : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-04-05 09:26:17,247 : MainThread : INFO : collected 5053 word types and 68 unique tags from a corpus of 68 examples and 65032 words\n",
      "2018-04-05 09:26:17,255 : MainThread : INFO : Loading a fresh vocabulary\n",
      "2018-04-05 09:26:17,279 : MainThread : INFO : min_count=2 retains 3292 unique words (65% of original 5053, drops 1761)\n",
      "2018-04-05 09:26:17,285 : MainThread : INFO : min_count=2 leaves 63271 word corpus (97% of original 65032, drops 1761)\n",
      "2018-04-05 09:26:17,313 : MainThread : INFO : deleting the raw counts dictionary of 5053 items\n",
      "2018-04-05 09:26:17,314 : MainThread : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2018-04-05 09:26:17,316 : MainThread : INFO : downsampling leaves estimated 51991 word corpus (82.2% of prior 63271)\n",
      "2018-04-05 09:26:17,317 : MainThread : INFO : estimated required memory for 3292 words and 300 dimensions: 9642000 bytes\n",
      "2018-04-05 09:26:17,347 : MainThread : INFO : resetting layer weights\n",
      "2018-04-05 09:26:17,435 : MainThread : INFO : training model with 4 workers on 3292 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=10 window=100\n",
      "2018-04-05 09:26:18,517 : MainThread : INFO : PROGRESS: at 0.80% examples, 76739 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:19,635 : MainThread : INFO : PROGRESS: at 1.57% examples, 74316 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:20,683 : MainThread : INFO : PROGRESS: at 2.62% examples, 83179 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:21,704 : MainThread : INFO : PROGRESS: at 3.62% examples, 87736 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:22,713 : MainThread : INFO : PROGRESS: at 4.52% examples, 89021 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:23,773 : MainThread : INFO : PROGRESS: at 5.52% examples, 90584 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:24,852 : MainThread : INFO : PROGRESS: at 6.35% examples, 89481 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:25,853 : MainThread : INFO : PROGRESS: at 7.30% examples, 90306 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:26,870 : MainThread : INFO : PROGRESS: at 8.23% examples, 90838 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:27,897 : MainThread : INFO : PROGRESS: at 9.18% examples, 91274 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:28,976 : MainThread : INFO : PROGRESS: at 10.17% examples, 91640 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:30,001 : MainThread : INFO : PROGRESS: at 11.08% examples, 91868 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:31,016 : MainThread : INFO : PROGRESS: at 12.12% examples, 92748 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:32,043 : MainThread : INFO : PROGRESS: at 13.12% examples, 93362 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:33,058 : MainThread : INFO : PROGRESS: at 14.02% examples, 93402 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:34,078 : MainThread : INFO : PROGRESS: at 15.02% examples, 93946 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:35,107 : MainThread : INFO : PROGRESS: at 15.80% examples, 93122 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:36,144 : MainThread : INFO : PROGRESS: at 16.80% examples, 93525 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:37,182 : MainThread : INFO : PROGRESS: at 17.80% examples, 93876 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:38,193 : MainThread : INFO : PROGRESS: at 18.73% examples, 93973 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:39,228 : MainThread : INFO : PROGRESS: at 19.67% examples, 93938 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:40,337 : MainThread : INFO : PROGRESS: at 20.68% examples, 94002 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:41,346 : MainThread : INFO : PROGRESS: at 21.68% examples, 94385 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:42,432 : MainThread : INFO : PROGRESS: at 22.68% examples, 94445 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:43,480 : MainThread : INFO : PROGRESS: at 23.67% examples, 94586 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:44,524 : MainThread : INFO : PROGRESS: at 24.62% examples, 94553 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:45,710 : MainThread : INFO : PROGRESS: at 25.57% examples, 94183 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:46,782 : MainThread : INFO : PROGRESS: at 26.68% examples, 94638 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:47,810 : MainThread : INFO : PROGRESS: at 27.57% examples, 94527 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:48,831 : MainThread : INFO : PROGRESS: at 28.62% examples, 94845 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:49,844 : MainThread : INFO : PROGRESS: at 29.62% examples, 95093 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:50,902 : MainThread : INFO : PROGRESS: at 30.62% examples, 95198 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:51,961 : MainThread : INFO : PROGRESS: at 31.62% examples, 95294 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:53,023 : MainThread : INFO : PROGRESS: at 32.62% examples, 95374 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:54,048 : MainThread : INFO : PROGRESS: at 33.62% examples, 95551 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:55,066 : MainThread : INFO : PROGRESS: at 34.40% examples, 95277 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-05 09:26:56,113 : MainThread : INFO : PROGRESS: at 35.35% examples, 95230 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:57,192 : MainThread : INFO : PROGRESS: at 36.35% examples, 95265 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:58,236 : MainThread : INFO : PROGRESS: at 37.35% examples, 95381 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:26:59,332 : MainThread : INFO : PROGRESS: at 38.35% examples, 95337 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:00,350 : MainThread : INFO : PROGRESS: at 39.35% examples, 95536 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:01,369 : MainThread : INFO : PROGRESS: at 40.35% examples, 95690 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:02,478 : MainThread : INFO : PROGRESS: at 41.35% examples, 95644 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:03,528 : MainThread : INFO : PROGRESS: at 42.35% examples, 95721 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:04,575 : MainThread : INFO : PROGRESS: at 43.35% examples, 95804 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-05 09:27:05,609 : MainThread : INFO : PROGRESS: at 44.23% examples, 95601 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:06,642 : MainThread : INFO : PROGRESS: at 45.23% examples, 95707 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:07,672 : MainThread : INFO : PROGRESS: at 46.23% examples, 95818 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:08,692 : MainThread : INFO : PROGRESS: at 47.17% examples, 95794 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:09,749 : MainThread : INFO : PROGRESS: at 48.17% examples, 95848 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:10,761 : MainThread : INFO : PROGRESS: at 49.18% examples, 96007 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:11,761 : MainThread : INFO : PROGRESS: at 50.12% examples, 96015 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:12,795 : MainThread : INFO : PROGRESS: at 51.12% examples, 96106 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:13,873 : MainThread : INFO : PROGRESS: at 52.12% examples, 96117 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:14,969 : MainThread : INFO : PROGRESS: at 53.02% examples, 95942 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:15,975 : MainThread : INFO : PROGRESS: at 53.90% examples, 95930 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:17,012 : MainThread : INFO : PROGRESS: at 54.90% examples, 96009 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:18,035 : MainThread : INFO : PROGRESS: at 55.90% examples, 96103 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:19,053 : MainThread : INFO : PROGRESS: at 56.85% examples, 96107 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:20,069 : MainThread : INFO : PROGRESS: at 57.85% examples, 96209 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:21,135 : MainThread : INFO : PROGRESS: at 58.85% examples, 96233 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:22,170 : MainThread : INFO : PROGRESS: at 59.85% examples, 96305 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:23,238 : MainThread : INFO : PROGRESS: at 60.85% examples, 96324 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:24,280 : MainThread : INFO : PROGRESS: at 61.85% examples, 96381 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-05 09:27:25,320 : MainThread : INFO : PROGRESS: at 62.67% examples, 96106 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:26,334 : MainThread : INFO : PROGRESS: at 63.68% examples, 96222 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:27,336 : MainThread : INFO : PROGRESS: at 64.62% examples, 96223 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:28,450 : MainThread : INFO : PROGRESS: at 65.67% examples, 96266 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:29,464 : MainThread : INFO : PROGRESS: at 66.62% examples, 96269 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:30,562 : MainThread : INFO : PROGRESS: at 67.67% examples, 96332 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:31,591 : MainThread : INFO : PROGRESS: at 68.68% examples, 96421 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:32,638 : MainThread : INFO : PROGRESS: at 69.67% examples, 96444 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:33,705 : MainThread : INFO : PROGRESS: at 70.67% examples, 96461 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:34,760 : MainThread : INFO : PROGRESS: at 71.62% examples, 96410 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:35,761 : MainThread : INFO : PROGRESS: at 72.40% examples, 96288 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:36,780 : MainThread : INFO : PROGRESS: at 73.47% examples, 96391 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:37,850 : MainThread : INFO : PROGRESS: at 74.40% examples, 96377 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:38,919 : MainThread : INFO : PROGRESS: at 75.52% examples, 96494 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:39,962 : MainThread : INFO : PROGRESS: at 76.40% examples, 96435 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:40,981 : MainThread : INFO : PROGRESS: at 77.40% examples, 96506 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:42,033 : MainThread : INFO : PROGRESS: at 78.40% examples, 96534 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:43,066 : MainThread : INFO : PROGRESS: at 79.35% examples, 96514 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:44,124 : MainThread : INFO : PROGRESS: at 80.35% examples, 96538 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:45,129 : MainThread : INFO : PROGRESS: at 81.30% examples, 96533 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:46,240 : MainThread : INFO : PROGRESS: at 82.30% examples, 96497 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:47,295 : MainThread : INFO : PROGRESS: at 83.30% examples, 96522 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:48,325 : MainThread : INFO : PROGRESS: at 84.30% examples, 96574 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:49,364 : MainThread : INFO : PROGRESS: at 85.30% examples, 96616 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:50,384 : MainThread : INFO : PROGRESS: at 86.23% examples, 96600 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:51,420 : MainThread : INFO : PROGRESS: at 87.30% examples, 96720 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:52,478 : MainThread : INFO : PROGRESS: at 88.30% examples, 96739 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:53,478 : MainThread : INFO : PROGRESS: at 89.30% examples, 96816 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:54,503 : MainThread : INFO : PROGRESS: at 90.23% examples, 96791 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-05 09:27:55,530 : MainThread : INFO : PROGRESS: at 91.12% examples, 96696 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:56,620 : MainThread : INFO : PROGRESS: at 92.12% examples, 96682 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:57,621 : MainThread : INFO : PROGRESS: at 93.12% examples, 96753 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:58,644 : MainThread : INFO : PROGRESS: at 94.12% examples, 96803 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:27:59,685 : MainThread : INFO : PROGRESS: at 95.12% examples, 96836 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:28:00,793 : MainThread : INFO : PROGRESS: at 96.17% examples, 96864 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:28:01,820 : MainThread : INFO : PROGRESS: at 97.17% examples, 96909 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:28:02,821 : MainThread : INFO : PROGRESS: at 98.18% examples, 96989 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:28:03,875 : MainThread : INFO : PROGRESS: at 99.17% examples, 96993 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-05 09:28:04,668 : MainThread : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-05 09:28:04,670 : MainThread : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-05 09:28:04,710 : MainThread : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-05 09:28:04,727 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-05 09:28:04,728 : MainThread : INFO : training on 13006400 raw words (10412046 effective words) took 107.3s, 97045 effective words/s\n",
      "2018-04-05 09:28:04,732 : MainThread : INFO : precomputing L2-norms of word weight vectors\n",
      "2018-04-05 09:28:04,801 : MainThread : INFO : saving Doc2Vec object under /home/marco/gdrive/research/nlp/data/v4/2015/doc2vec.model.2015, separately None\n",
      "2018-04-05 09:28:04,805 : MainThread : INFO : not storing attribute syn0norm\n",
      "2018-04-05 09:28:04,807 : MainThread : INFO : not storing attribute cum_table\n",
      "2018-04-05 09:28:04,930 : MainThread : INFO : saved /home/marco/gdrive/research/nlp/data/v4/2015/doc2vec.model.2015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model  /home/marco/gdrive/research/nlp/data/v4/2015/doc2vec.model.2015\n"
     ]
    }
   ],
   "source": [
    "# creating doc2vec model for the current year\n",
    "model = doc2vec.Doc2Vec(size=300, window=100, min_count=2, iter=200, workers=4, dm=1, negative=10)\n",
    "model.build_vocab(docs)\n",
    "model.train(docs, total_examples=model.corpus_count, epochs=model.iter)\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# save model on disk\n",
    "nameModel = \"doc2vec.model.\" + str(year)\n",
    "fullname = path.join(dirFull,nameModel)\n",
    "print(\"Saving model \", fullname)\n",
    "model.save(fullname)\n",
    "model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "\n",
    "# save mapping id-->tag on disk\n",
    "#nameMap = \"mapping.doc2vec.\" + str(year)\n",
    "#fullname = path.join(dirFull,nameMap)\n",
    "#print(\"Saving mapping \", fullname)\n",
    "#f = open(fullname, \"w\")\n",
    "#writer = csv.writer(f)\n",
    "#for i in range(len(absID)):\n",
    "#    writer.writerow([i,absID[i]])\n",
    "#f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "print(len(model.docvecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task 3: Using doc2vec model\n",
    "\n",
    "Here, we upload a doc2vec model for a specific year and use it to build a distance matrix. In addition, to separate model creation from model use, we need to find out which documents belong to the corpus.\n",
    "\n",
    "**Rem.:** There are two ways of using a doc2vec model: i. Getting the embedding of a document stored within the doc2vec model. Obviously, this requires that the document was actually used in the doc2vec creation phase. We also need to know the tag associated to that document. We can then refer to the embedding using the tag; (ii) Inferring an embedding vector and treating the document as a new, unseen one. In this case, whether the document was used or not durign the doc2vec model creation phase does not matter, since the model will provide an embedding for a document, treating it as unseen. \n",
    "\n",
    "While approach i. is deterministic (it always returns the same embedding for a document), approach ii. is stochastic (the embedding vector is different every time we ask to compute the inferred vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-05 09:34:02,308 : MainThread : INFO : loading Doc2Vec object from /home/marco/gdrive/research/nlp/data/v4/2015/doc2vec.model.2015\n",
      "2018-04-05 09:34:02,393 : MainThread : INFO : loading wv recursively from /home/marco/gdrive/research/nlp/data/v4/2015/doc2vec.model.2015.wv.* with mmap=None\n",
      "2018-04-05 09:34:02,396 : MainThread : INFO : setting ignored attribute syn0norm to None\n",
      "2018-04-05 09:34:02,398 : MainThread : INFO : loading docvecs recursively from /home/marco/gdrive/research/nlp/data/v4/2015/doc2vec.model.2015.docvecs.* with mmap=None\n",
      "2018-04-05 09:34:02,401 : MainThread : INFO : setting ignored attribute cum_table to None\n",
      "2018-04-05 09:34:02,402 : MainThread : INFO : loaded /home/marco/gdrive/research/nlp/data/v4/2015/doc2vec.model.2015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model  /home/marco/gdrive/research/nlp/data/v4/2015/doc2vec.model.2015\n",
      "The model contains 68 vectors.\n"
     ]
    }
   ],
   "source": [
    "# define the year and read corresponding doc2vec model\n",
    "year = \"2015\"\n",
    "dirFull = path.join(prefix,perDayFolders) + year\n",
    "fullname = dirFull + \"/doc2vec.model.\" + year\n",
    "print(\"Loading model \", fullname)\n",
    "modelDoc2Vec = doc2vec.Doc2Vec.load(fullname)\n",
    "print(\"The model contains {0} vectors.\".format(len(modelDoc2Vec.docvecs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-05 09:34:06,008 : MainThread : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('morning', 0.8003968000411987),\n",
       " ('session', 0.5685198307037354),\n",
       " ('comes', 0.5152820944786072),\n",
       " ('distributing', 0.48078060150146484),\n",
       " ('essential', 0.44736558198928833),\n",
       " ('happen', 0.44607722759246826),\n",
       " ('instructions', 0.4353036880493164),\n",
       " ('question', 0.3995822072029114),\n",
       " ('pharmaceuticals', 0.3972008526325226),\n",
       " ('pinnacle', 0.3752984404563904)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just a little test\n",
    "modelDoc2Vec.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "modelDoc2Vec.wv.vocab # to get the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task 3: Distance Matrix Computation\n",
    "\n",
    "We can use two approaches to similarity computation:\n",
    "- Using the actual doc2vec embedding vector\n",
    "- Using an inferred vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Using the actual doc2vec embedding vector\n",
    "\n",
    "Each document in the corpus is now associated to a vector, contained in the doc2vec model. We can simply get the vector by using `modelDoc2Vec[doc]` to get the embedding of the document. However, the problem here is that, if in the model creation phase we eliminated, e.g., all the words that appear only once (`min_count=2`), then it might happen that we cannot get back the actual vector associated to `doc` (an error message notifies that a given word is not in the vocabulary.) We thus need to screen the document and eliminate all the words that are not in the vocabulary. \n",
    "\n",
    "Alternatively, and much simpler, we can get the tag of each document in the current corpus, and directly obtain the embedding of that document using `modelDoc2Vec.docvecs[tag]`. Since here we are accessing a pre-computed embedding, without using the actual document, we do not have the problem described above. Note that, in this case, we do not even need to load the document in memory, since with the tag it will suffice.\n",
    "\n",
    "Let us first get a list of documents tag to be used to compute the distance matrix. Which documents should be included here depends on the strategy used. For now, assume we want to use all the documents of a given year. \n",
    "\n",
    "__Note:__ In this case, we do not even need to load the corpus. We just need to create a list of tags corresponding to the documents we want to use in the distance matrix computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n"
     ]
    }
   ],
   "source": [
    "# get absolute tag for all documents belonging to a given year\n",
    "year = \"2015\"\n",
    "tagList = []\n",
    "nRows = len(dfMap)\n",
    "for row in range(nRows):\n",
    "    #print(dfMap.iloc[row])\n",
    "    if dfMap.iloc[row][\"year\"] == int(year):\n",
    "        #print(\"file \", dfMap.iloc[row][\"name\"], \" selected\")\n",
    "        tagList.append(dfMap.iloc[row][\"tag\"])\n",
    "print(tagList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sorted(corpus2tag.values()))\n",
    "print(sorted(corpus2tag.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, compute the pairwise distances among all the documents in the `tagList`. The distance matrix is stored in long format in a disk file. Note that we store only the upper diagonal matrix (since distances are symmetric here). The format is:\n",
    "- first row: number of documents in this corpus, e.g., $n$. Thus, the number of pairwise distances in the file is $n(n+1)/2$.)\n",
    "- second row: list of tagged documents included in this distance matrix ($n$ elements)\n",
    "- from row 3 to $n(n+1)/2 + 3$, the following table:\n",
    "\n",
    "|from|to|distance|\n",
    "|----|----|-----|\n",
    "|0|0|0|\n",
    "|0|1|0.23|\n",
    "|..|..|..|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix saved ::  /home/marco/gdrive/research/nlp/data/v4/2015/doc2vecDistMatrix.txt.2015\n"
     ]
    }
   ],
   "source": [
    "nDocs = len(tagList)\n",
    "nameMatrix = \"doc2vecDistMatrix.txt.\" + str(year)\n",
    "fullname = path.join(dirFull,nameMatrix)\n",
    "\n",
    "f = open(fullname, \"w\")\n",
    "writer = csv.writer(f)\n",
    "writer.writerow([nDocs])\n",
    "writer.writerow(tagList)\n",
    "vals = [ [0.0 for i in range(nDocs)] for j in range(nDocs)]\n",
    "    \n",
    "for i in range(nDocs):\n",
    "    tag_i = tagList[i]\n",
    "        \n",
    "    for j in range(i,nDocs):\n",
    "        tag_j = tagList[j]\n",
    "        val = round(1.0-modelDoc2Vec.docvecs.similarity(str(tag_i),str(tag_j)), 4)\n",
    "        writer.writerow([tag_i, tag_j, val])\n",
    "\n",
    "f.close()\n",
    "print(\"Distance Matrix saved :: \", fullname)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Using an inferred vector\n",
    "\n",
    "[__Note:__ To use this part, we need to upload the corpus itself. It is not enough to have the tags associated to the documents of the corpus]. With _gensim_, it is possible to infer a vector associated to an (unseen) document. In this case, whether or not all the words of a document are in the vocabulary no longer matters. One could then create an inferred vector for each document in the corpus and find the closest document in the corpus w.r.t. the inferred vector. If the doc2vec model works, the closest document should always be itself. To test the quality of the doc2vec model used, we can then count how many time the closest document to each inferred vector is actually the original document itself.\n",
    "\n",
    "Let us run a test to determine whether the doc2vec model is accurate. We compute the inferred vector for each document in the corpus. Next, we find the most similar document to each inferred vector. If the doc2vec model works, each document should return **itself** as most similar. Finally, we count how many times this happens (ideally, all the times).\n",
    "\n",
    "At this stage, the accuracy of the answer seems to depend on the number of iterations used to generate the inferred vector.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering year  2015\n",
      "Corpus with    28 documents.\n",
      "List of Tags ::  [982, 981, 986, 985, 996, 972, 992, 987, 976, 998, 999, 980, 997, 991, 990, 984, 983, 995, 977, 989, 973, 988, 993, 979, 974, 975, 994, 978]\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "listOfTags = []\n",
    "print(\"Considering year \", year)\n",
    "dirFull = path.join(prefix,perDayFolders) + str(year)\n",
    "\n",
    "for ff in listdir(dirFull):\n",
    "    filteredList = path.join(dirFull,ff) + \"/*.txt.pre\"\n",
    "    for f in glob.glob(filteredList):\n",
    "        name = f.split(\"/\")[-1]\n",
    "        name = name[:-4]\n",
    "        listOfTags.append(file2tag[name])\n",
    "\n",
    "        fullname = path.join(dirFull, ff, f)\n",
    "        fToken = open(fullname, \"r\")\n",
    "        readerDoc = csv.reader(fToken)\n",
    "        doc = next(readerDoc)\n",
    "        fToken.close()\n",
    "        corpus.append(doc)\n",
    "\n",
    "print(\"Corpus with {0:5d} documents.\".format(len(corpus)))\n",
    "print(\"List of Tags :: \", listOfTags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ranks = []\n",
    "for id in range(len(corpus)):\n",
    "\n",
    "    inferred_vector = modelDoc2Vec.infer_vector(corpus[id], steps=200)\n",
    "    tag = listOfTags[id] # this is int\n",
    "    #print(inferred_vector)\n",
    "    sims = modelDoc2Vec.docvecs.most_similar([inferred_vector], topn=len(modelDoc2Vec.docvecs))\n",
    "    rank = [i for i,j in sims].index(str(tag))\n",
    "    print(\"Vector {0:3d} : Rank = {1:3d} with score {2:5.3f}\".format(id,rank,sims[rank][1]))\n",
    "    ranks.append(rank)\n",
    "    \n",
    "collections.Counter(ranks) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task 4: Clustering\n",
    "\n",
    "We now use the distance matrix saved on disk within each folder to carry out a specific type of analysis. For now, we use hierarchical clustering. The goal, though, is to see how clusters change over time and other type of analysis to study correlations among PR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as ssd\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster, cophenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n"
     ]
    }
   ],
   "source": [
    "### read distance matrix\n",
    "year = \"2015\"\n",
    "nameMatrix = \"doc2vecDistMatrix.txt.\" + str(year)\n",
    "fullname = path.join(dirFull,nameMatrix)\n",
    "\n",
    "f = open(fullname, \"r\")\n",
    "reader = csv.reader(f)\n",
    "nDocs = int(next(reader)[0])\n",
    "auxList = next(reader)\n",
    "tagList = [int(auxList[i]) for i in range(len(auxList))]\n",
    "\n",
    "distMatrix = [ [0.0 for i in range(nDocs)] for j in range(nDocs)]\n",
    "i = -1\n",
    "j = 0\n",
    "for row in reader:\n",
    "    if j % nDocs == 0:\n",
    "        i += 1\n",
    "        j = i\n",
    "    ix = int(row[0])\n",
    "    jx = int(row[1])\n",
    "    d = float(row[2])\n",
    "\n",
    "    distMatrix[i][j] = d\n",
    "    distMatrix[j][i] = d\n",
    "    \n",
    "    #print(\"distance from {0:5d} ({1:5d}) to {2:5d} ({3:5d}) is {4:7.4f}\".format(ix,i, jx, j,d))\n",
    "    j += 1\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ward      ] Cophenetic =  0.76\n",
      "[ median    ] Cophenetic =  0.82\n",
      "[ average   ] Cophenetic =  0.86\n",
      "[ single    ] Cophenetic =  0.84\n",
      "[ complete  ] Cophenetic =  0.70\n"
     ]
    }
   ],
   "source": [
    "distArray = ssd.squareform(np.asmatrix(distMatrix), checks=False)\n",
    "methods = [\"ward\", \"median\", \"average\", \"single\", \"complete\"]\n",
    "bestVal = 0.0\n",
    "bestMethod = \" \"\n",
    "for mm in methods:\n",
    "    Z = linkage(distArray, method=mm, optimal_ordering=True)\n",
    "    c, cophDist = cophenet(Z, distArray)\n",
    "    print(\"[ {0:10s}] Cophenetic = {1:5.2f}\".format(mm,c))\n",
    "    if c > bestVal:\n",
    "        bestVal = c\n",
    "        bestMethod = mm\n",
    "        \n",
    "Z = linkage(distArray, method=bestMethod, optimal_ordering=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABaIAAAJPCAYAAACO4KMsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAwAAAAAwKkE0AAAAAACj+j9xy7ETKH+q+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f478c507ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "plt.title(\"Hierarchical Clustering Press Releases\")\n",
    "pp= dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90,\n",
    "    leaf_font_size=8.,\n",
    "    show_leaf_counts=True,\n",
    "    get_leaves=True,\n",
    "#    truncate_mode=\"level\",\n",
    "#    p = 5\n",
    ")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "An alternative approach is based on the use of a k-mean clustering algorithm from the nltk library. The algorithm uses the vectors associated to each document (rather than the distance matrix.) Therefore, we need to get the embeddings of the documents in the current corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.cluster import KMeansClusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read doc2vec model\n",
    "year = \"2015\"\n",
    "dirFull = path.join(prefix,perDayFolders) + year\n",
    "fullname = dirFull + \"/doc2vec.model.\" + year\n",
    "print(\"Loading model \", fullname)\n",
    "modelDoc2Vec = doc2vec.Doc2Vec.load(fullname)\n",
    "print(\"The model contains {0} vectors.\".format(len(modelDoc2Vec.docvecs)))\n",
    "\n",
    "nameMatrix = \"doc2vecDistMatrix.txt.\" + str(year)\n",
    "fullname = path.join(dirFull,nameMatrix)\n",
    "# get taglist\n",
    "f = open(fullname, \"r\")\n",
    "reader = csv.reader(f)\n",
    "nDocs = int(next(reader)[0])\n",
    "auxList = next(reader)\n",
    "tagList = [int(auxList[i]) for i in range(len(auxList))]\n",
    "f.close()\n",
    "print(\"Taglist is = \", tagList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters Labels =  [3, 2, 0, 2, 0, 0, 1, 2, 3, 2, 3, 1, 2, 2, 0, 2, 2, 2, 3, 2, 1, 3, 3, 1, 3, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 4\n",
    "vectors = [modelDoc2Vec.docvecs[str(i)] for i in tagList]\n",
    "kclusterer = KMeansClusterer(num_clusters,\n",
    "                            distance =nltk.cluster.util.cosine_distance,\n",
    "                            repeats=500)\n",
    "labels = kclusterer.cluster(vectors, assign_clusters=True)\n",
    "print(\"Clusters Labels = \", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis of Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readDistMatrix(year):\n",
    "\n",
    "    nameMatrix = \"doc2vecDistMatrix.txt.\" + str(year)\n",
    "\n",
    "    fullname = path.join(prefix,perDayFolders,year,nameMatrix)\n",
    "    print(\"Fullname = \", fullname)\n",
    "    f = open(fullname, \"r\")\n",
    "    reader = csv.reader(f)\n",
    "    nDocs = int(next(reader)[0])\n",
    "    print(\"NDocs = \", nDocs)\n",
    "    distMatrix = [ [0.0 for i in range(nDocs)] for j in range(nDocs)]\n",
    "    auxList = next(reader)\n",
    "    tagList = [int(auxList[i]) for i in range(len(auxList))]\n",
    "    i = -1\n",
    "    j =  0\n",
    "    for row in reader:\n",
    "        if j % nDocs == 0:\n",
    "            i += 1\n",
    "            j  = i\n",
    "        ix = int(row[0])\n",
    "        jx = int(row[1])\n",
    "        d  = float(row[2])\n",
    "        distMatrix[i][j] = d\n",
    "        distMatrix[j][i] = d\n",
    "        j += 1\n",
    "    f.close()\n",
    "    return distMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fullname =  /home/marco/gdrive/research/nlp/data/v4/2006/doc2vecDistMatrix.txt.2006\n",
      "NDocs =  90\n",
      "[0.         0.05454545 0.10909091 0.16363636 0.21818182 0.27272727\n",
      " 0.32727273 0.38181818 0.43636364 0.49090909 0.54545455 0.6       ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAFKCAYAAABRtSXvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b47757a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distMatrix = readDistMatrix(\"2006\")\n",
    "np.mean(distMatrix)\n",
    "\n",
    "dd = [distMatrix[i][j] for i in range(nDocs) for j in range(nDocs)]\n",
    "\n",
    "bins = np.linspace(0, 0.6, 12)\n",
    "plt.hist(dd,bins=bins,alpha=0.5,edgecolor=\"black\",normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the same company: Let us examine the distance within the same cik code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
